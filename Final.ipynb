{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiv2H1DM3fxejmZxcCjx/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GutemaB2015/Gutema-thesis/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq3kt3xlVebt",
        "outputId": "b179b52a-f1e4-49ba-ee51-a4166ba0e617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classiffier Accuracy: 0.965\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       283\n",
            "           1       1.00      0.91      0.95       234\n",
            "           2       0.80      1.00      0.89        83\n",
            "\n",
            "    accuracy                           0.96       600\n",
            "   macro avg       0.93      0.97      0.95       600\n",
            "weighted avg       0.97      0.96      0.97       600\n",
            "\n",
            "Macro Precision: 0.9326923076923078\n",
            "Macro Recall: 0.9700854700854701\n",
            "Macro F1 Score: 0.9469068896625155\n",
            "Random Forest Classifier Accuracy: 0.9666666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       283\n",
            "           1       1.00      0.91      0.95       234\n",
            "           2       0.80      1.00      0.89        83\n",
            "\n",
            "    accuracy                           0.96       600\n",
            "   macro avg       0.93      0.97      0.95       600\n",
            "weighted avg       0.97      0.96      0.97       600\n",
            "\n",
            "Macro Precision: 0.9326923076923078\n",
            "Macro Recall: 0.9700854700854701\n",
            "Macro F1 Score: 0.9469068896625155\n",
            "Naive Bayes's  Algorithm Accuracy:  0.9233333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       283\n",
            "           1       1.00      0.91      0.95       234\n",
            "           2       0.80      1.00      0.89        83\n",
            "\n",
            "    accuracy                           0.96       600\n",
            "   macro avg       0.93      0.97      0.95       600\n",
            "weighted avg       0.97      0.96      0.97       600\n",
            "\n",
            "Macro Precision: 0.9326923076923078\n",
            "Macro Recall: 0.9700854700854701\n",
            "Macro F1 Score: 0.9469068896625155\n",
            "K-Nearest Neighbour Accuracy: 0.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       283\n",
            "           1       1.00      0.91      0.95       234\n",
            "           2       0.80      1.00      0.89        83\n",
            "\n",
            "    accuracy                           0.96       600\n",
            "   macro avg       0.93      0.97      0.95       600\n",
            "weighted avg       0.97      0.96      0.97       600\n",
            "\n",
            "Macro Precision: 0.9326923076923078\n",
            "Macro Recall: 0.9700854700854701\n",
            "Macro F1 Score: 0.9469068896625155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression algorithm Accuracy: 0.9633333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       283\n",
            "           1       0.96      0.94      0.95       234\n",
            "           2       0.95      0.92      0.93        83\n",
            "\n",
            "    accuracy                           0.96       600\n",
            "   macro avg       0.96      0.95      0.96       600\n",
            "weighted avg       0.96      0.96      0.96       600\n",
            "\n",
            "Macro Precision: 0.9602219017864296\n",
            "Macro Recall: 0.950766673956252\n",
            "Macro F1 Score: 0.9552552850072188\n",
            "SVM Classifier Accuracy: 0.975\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       283\n",
            "           1       0.96      0.98      0.97       234\n",
            "           2       0.95      0.93      0.94        83\n",
            "\n",
            "    accuracy                           0.97       600\n",
            "   macro avg       0.97      0.96      0.97       600\n",
            "weighted avg       0.98      0.97      0.98       600\n",
            "\n",
            "Macro Precision: 0.9684016170650294\n",
            "Macro Recall: 0.9640696821291993\n",
            "Macro F1 Score: 0.9661436406665201\n"
          ]
        }
      ],
      "source": [
        "#list of imported libraries.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# DatasetUrl\n",
        "DatasetUrl = 'https://raw.githubusercontent.com/GutemaB2015/Gutema-thesis/main/FillDataset.csv'\n",
        "data = pd.read_csv(DatasetUrl)\n",
        "\n",
        "\n",
        "\n",
        "# Extraxt the features you want to base the foundation of our model training\n",
        "features = ['Max_Packet_Length','Fwd_Packet_Length_Max','Flow_Packets_Sec','Flow_Bytes_Sec','Packet_Length_Std','Packet_Length_Variance','Flow_IAT_Max'\n",
        "           ,'Fwd_IAT_Max','Subflow_Fwd_Bytes','Fwd_Packet_Length_Std','Bwd_Packets_Sec','min_seg_size_forward','Init_Win_bytes_backward','Average_Packet_Size'\n",
        "           ,'Packet_Length_Mean','Fwd_IAT_Total','Flow_IAT_Std','Fwd_IAT_Std','Avg_Fwd_Segment_Size','Fwd_Packet_Length_Mean','Fwd_Header_Length'\n",
        "           ,'Fwd_IAT_Mean','Flow_IAT_Mean','Idle_Max','Idle_Mean','Fwd_Packets_Sec','Active_Std','Active_Max','Active_Min']\n",
        "\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['Label'] = label_encoder.fit_transform(data['Label'])\n",
        "data['Label'].fillna(data['Label'].median(), inplace=True)\n",
        "AttackLabel = data[\"Label\"]\n",
        "\n",
        "data = data.drop(\"Total_Length_of_Bwd_Packets\", axis=1)\n",
        "data = data.drop(\"Fwd_Packet_Length_Min\", axis=1)\n",
        "data = data.drop(\"Bwd_Packet_Length_Max\", axis=1)\n",
        "data = data.drop(\"Bwd_Packet_Length_Min\", axis=1)\n",
        "data = data.drop(\"Bwd_Packet_Length_Mean\", axis=1)\n",
        "data = data.drop(\"Bwd_Packet_Length_Std\", axis=1)\n",
        "data = data.drop(\"Flow_IAT_Min\", axis=1)\n",
        "data = data.drop(\"Fwd_IAT_Min\", axis=1)\n",
        "\n",
        "data = data.drop(\"Bwd_IAT_Total\", axis=1)\n",
        "data = data.drop(\"Bwd_IAT_Mean\", axis=1)\n",
        "data = data.drop(\"Bwd_IAT_Std\", axis=1)\n",
        "data = data.drop(\"Bwd_IAT_Max\", axis=1)\n",
        "data = data.drop(\"Bwd_IAT_Min\", axis=1)\n",
        "data = data.drop(\"Bwd_Header_Length\", axis=1)\n",
        "data = data.drop(\"Min_Packet_Length\", axis=1)\n",
        "data = data.drop(\"SYN_Flag_Count\", axis=1)\n",
        "data = data.drop(\"Down_Up_Ratio\", axis=1)\n",
        "data = data.drop(\"Avg_Bwd_Segment_Size\", axis=1)\n",
        "data = data.drop(\"Subflow_Fwd_Packets\", axis=1)\n",
        "data = data.drop(\"Subflow_Bwd_Packets\", axis=1)\n",
        "data = data.drop(\"Subflow_Bwd_Bytes\", axis=1)\n",
        "data = data.drop(\"Init_Win_bytes_forward\", axis=1)\n",
        "data = data.drop(\"act_data_pkt_fwd\", axis=1)\n",
        "data = data.drop(\"Active_Mean\", axis=1)\n",
        "data = data.drop(\"Idle_Std\", axis=1)\n",
        "data = data.drop(\"Idle_Min\", axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Replace missing values with the mean of the column\n",
        "data['Fwd_Packets_Sec'].fillna(data['Fwd_Packets_Sec'].median(), inplace=True)\n",
        "data['Idle_Mean'].fillna(data['Idle_Mean'].median(), inplace=True)\n",
        "data['Idle_Max'].fillna(data['Idle_Max'].median(), inplace=True)\n",
        "data['Flow_IAT_Mean'].fillna(data['Flow_IAT_Mean'].median(), inplace=True)\n",
        "data['Active_Std'].fillna(data['Active_Std'].median(), inplace=True)\n",
        "data['Active_Max'].fillna(data['Active_Max'].median(), inplace=True)\n",
        "data['Active_Min'].fillna(data['Active_Min'].median(), inplace=True)\n",
        "data['Fwd_IAT_Mean'].fillna(data['Fwd_IAT_Mean'].median(), inplace=True)\n",
        "data['Fwd_Header_Length'].fillna(data['Fwd_Header_Length'].median(), inplace=True)\n",
        "data['Fwd_Packet_Length_Mean'].fillna(data['Fwd_Packet_Length_Mean'].median(), inplace=True)\n",
        "data['Avg_Fwd_Segment_Size'].fillna(data['Avg_Fwd_Segment_Size'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_IAT_Std'].fillna(data['Fwd_IAT_Std'].median(), inplace=True)\n",
        "data['Fwd_IAT_Total'].fillna(data['Fwd_IAT_Total'].median(), inplace=True)\n",
        "data['Flow_IAT_Std'].fillna(data['Flow_IAT_Std'].median(), inplace=True)\n",
        "data['Packet_Length_Mean'].fillna(data['Packet_Length_Mean'].median(), inplace=True)\n",
        "data['Average_Packet_Size'].fillna(data['Average_Packet_Size'].median(), inplace=True)\n",
        "data['Init_Win_bytes_backward'].fillna(data['Init_Win_bytes_backward'].median(), inplace=True)\n",
        "data['min_seg_size_forward'].fillna(data['min_seg_size_forward'].median(), inplace=True)\n",
        "data['Bwd_Packets_Sec'].fillna(data['Bwd_Packets_Sec'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_Packet_Length_Std'].fillna(data['Fwd_Packet_Length_Std'].median(), inplace=True)\n",
        "data['Subflow_Fwd_Bytes'].fillna(data['Subflow_Fwd_Bytes'].median(), inplace=True)\n",
        "data['Fwd_IAT_Max'].fillna(data['Fwd_IAT_Max'].median(), inplace=True)\n",
        "data['Flow_IAT_Max'].fillna(data['Flow_IAT_Max'].median(), inplace=True)\n",
        "data['Packet_Length_Variance'].fillna(data['Packet_Length_Variance'].median(), inplace=True)\n",
        "data['Packet_Length_Std'].fillna(data['Packet_Length_Std'].median(), inplace=True)\n",
        "data['Flow_Bytes_Sec'].fillna(data['Flow_Bytes_Sec'].median(), inplace=True)\n",
        "data['Flow_Packets_Sec'].fillna(data['Flow_Packets_Sec'].median(), inplace=True)\n",
        "data['Fwd_Packet_Length_Max'].fillna(data['Fwd_Packet_Length_Max'].median(), inplace=True)\n",
        "data['Max_Packet_Length'].fillna(data['Max_Packet_Length'].median(), inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], AttackLabel, test_size=0.2, random_state=1)\n",
        "\n",
        "\n",
        "#DEscision Tree Accuracy\n",
        "dectreClassifier = DecisionTreeClassifier(criterion=\"entropy\",min_samples_split=2,max_depth=2,min_samples_leaf=5)\n",
        "dectreClassifier = dectreClassifier.fit(X_train,y_train)\n",
        "y_pred = dectreClassifier.predict(X_test)\n",
        "print(\"Decision Tree Classiffier Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "# Print extracted metrics\n",
        "print(\"Macro Precision:\", precision)\n",
        "print(\"Macro Recall:\", recall)\n",
        "print(\"Macro F1 Score:\", f1_score)\n",
        "\n",
        "\n",
        "# Create a logistic regression model\n",
        "rmfClassifier = RandomForestClassifier(n_estimators=20, max_depth=2,min_samples_split=20, max_features = 10)\n",
        "rmfClassifier.fit(X_train, y_train)\n",
        "predictions = rmfClassifier.predict(X_test)\n",
        "print('Random Forest Classifier Accuracy:', rmfClassifier.score(X_test, y_test))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "# Print extracted metrics\n",
        "print(\"Macro Precision:\", precision)\n",
        "print(\"Macro Recall:\", recall)\n",
        "print(\"Macro F1 Score:\", f1_score)\n",
        "\n",
        "\n",
        "# create gaussian naive bayes classifier\n",
        "naiveBayes = GaussianNB()\n",
        "naiveBayes.fit(X_train,y_train)\n",
        "naiveBayesPreddiction = naiveBayes.predict(X_test)\n",
        "print(\"Naive Bayes's  Algorithm Accuracy: \",metrics.accuracy_score(y_test,naiveBayesPreddiction))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "# Print extracted metrics\n",
        "print(\"Macro Precision:\", precision)\n",
        "print(\"Macro Recall:\", recall)\n",
        "print(\"Macro F1 Score:\", f1_score)\n",
        "\n",
        "\n",
        "#K-Nearest Neighbour Algorithm\n",
        "knClassifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knClassifier.fit(X_train, y_train)\n",
        "predictions = knClassifier.predict(X_test)\n",
        "print('K-Nearest Neighbour Accuracy:', knClassifier.score(X_test, y_test))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "# Print extracted metrics\n",
        "print(\"Macro Precision:\", precision)\n",
        "print(\"Macro Recall:\", recall)\n",
        "print(\"Macro F1 Score:\", f1_score)\n",
        "\n",
        "\n",
        "# Logistic Regression algorithm\n",
        "logRegression = LogisticRegression(penalty='l2', C=1.0,max_iter=400)\n",
        "logRegression.fit(X_train, y_train)\n",
        "y_pred = logRegression.predict(X_test)\n",
        "print(\"Logistic Regression algorithm Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "# Print extracted metrics\n",
        "print(\"Macro Precision:\", precision)\n",
        "print(\"Macro Recall:\", recall)\n",
        "print(\"Macro F1 Score:\", f1_score)\n",
        "\n",
        "\n",
        "\n",
        "# Create an SVM classifier\n",
        "svmClassifier = SVC(kernel='rbf', C = 200)\n",
        "svmClassifier.fit(X_train, y_train)\n",
        "y_pred = svmClassifier.predict(X_test)\n",
        "print(\"SVM Classifier Accuracy:\", svmClassifier.score(X_test, y_test))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "# Print extracted metrics\n",
        "print(\"Macro Precision:\", precision)\n",
        "print(\"Macro Recall:\", recall)\n",
        "print(\"Macro F1 Score:\", f1_score)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}